{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4645c1df",
   "metadata": {},
   "source": [
    "# Conditional GLOW for Cell Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2064f8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Input dimension: 89, Number of classes: 4\n",
      "Epoch 1/150, Loss: 168.5968\n",
      "Epoch 2/150, Loss: 141.0645\n",
      "Epoch 3/150, Loss: 118.6972\n",
      "Epoch 4/150, Loss: 105.6923\n",
      "Epoch 5/150, Loss: 97.3759\n",
      "Epoch 6/150, Loss: 89.3348\n",
      "Epoch 7/150, Loss: 84.1397\n",
      "Epoch 8/150, Loss: 79.4649\n",
      "Epoch 9/150, Loss: 75.3399\n",
      "Epoch 10/150, Loss: 71.6551\n",
      "Epoch 11/150, Loss: 69.3471\n",
      "Epoch 12/150, Loss: 67.0650\n",
      "Epoch 13/150, Loss: 65.5853\n",
      "Epoch 14/150, Loss: 63.2964\n",
      "Epoch 15/150, Loss: 61.0782\n",
      "Epoch 16/150, Loss: 59.3868\n",
      "Epoch 17/150, Loss: 57.0311\n",
      "Epoch 18/150, Loss: 56.3959\n",
      "Epoch 19/150, Loss: 55.7575\n",
      "Epoch 20/150, Loss: 54.3217\n",
      "Epoch 21/150, Loss: 52.5229\n",
      "Epoch 22/150, Loss: 52.0908\n",
      "Epoch 23/150, Loss: 49.9148\n",
      "Epoch 24/150, Loss: 49.0820\n",
      "Epoch 25/150, Loss: 48.5599\n",
      "Epoch 26/150, Loss: 48.0411\n",
      "Epoch 27/150, Loss: 46.0734\n",
      "Epoch 28/150, Loss: 45.2139\n",
      "Epoch 29/150, Loss: 46.0345\n",
      "Epoch 30/150, Loss: 44.9313\n",
      "Epoch 31/150, Loss: 42.0675\n",
      "Epoch 32/150, Loss: 41.6909\n",
      "Epoch 33/150, Loss: 40.6379\n",
      "Epoch 34/150, Loss: 40.4868\n",
      "Epoch 35/150, Loss: 39.8825\n",
      "Epoch 36/150, Loss: 38.2144\n",
      "Epoch 37/150, Loss: 37.7530\n",
      "Epoch 38/150, Loss: 37.9360\n",
      "Epoch 39/150, Loss: 37.7918\n",
      "Epoch 40/150, Loss: 36.6541\n",
      "Epoch 41/150, Loss: 34.8075\n",
      "Epoch 42/150, Loss: 34.8236\n",
      "Epoch 43/150, Loss: 32.5839\n",
      "Epoch 44/150, Loss: 32.6467\n",
      "Epoch 45/150, Loss: 32.6357\n",
      "Epoch 46/150, Loss: 32.1650\n",
      "Epoch 47/150, Loss: 30.9160\n",
      "Epoch 48/150, Loss: 31.6342\n",
      "Epoch 49/150, Loss: 30.5881\n",
      "Epoch 50/150, Loss: 30.1876\n",
      "Epoch 51/150, Loss: 29.2937\n",
      "Epoch 52/150, Loss: 30.2442\n",
      "Epoch 53/150, Loss: 28.7264\n",
      "Epoch 54/150, Loss: 29.5657\n",
      "Epoch 55/150, Loss: 27.7152\n",
      "Epoch 56/150, Loss: 27.0189\n",
      "Epoch 57/150, Loss: 26.7138\n",
      "Epoch 58/150, Loss: 25.8157\n",
      "Epoch 59/150, Loss: 25.4135\n",
      "Epoch 60/150, Loss: 24.7599\n",
      "Epoch 61/150, Loss: 24.6584\n",
      "Epoch 62/150, Loss: 23.9847\n",
      "Epoch 63/150, Loss: 23.8177\n",
      "Epoch 64/150, Loss: 24.0168\n",
      "Epoch 65/150, Loss: 22.3781\n",
      "Epoch 66/150, Loss: 23.3176\n",
      "Epoch 67/150, Loss: 22.8931\n",
      "Epoch 68/150, Loss: 21.0578\n",
      "Epoch 69/150, Loss: 21.2512\n",
      "Epoch 70/150, Loss: 21.0695\n",
      "Epoch 71/150, Loss: 20.0928\n",
      "Epoch 72/150, Loss: 19.2116\n",
      "Epoch 73/150, Loss: 20.2020\n",
      "Epoch 74/150, Loss: 19.1125\n",
      "Epoch 75/150, Loss: 18.8937\n",
      "Epoch 76/150, Loss: 18.9020\n",
      "Epoch 77/150, Loss: 17.7253\n",
      "Epoch 78/150, Loss: 17.8868\n",
      "Epoch 79/150, Loss: 15.8898\n",
      "Epoch 80/150, Loss: 17.0961\n",
      "Epoch 81/150, Loss: 18.4503\n",
      "Epoch 82/150, Loss: 17.0531\n",
      "Epoch 83/150, Loss: 17.0944\n",
      "Epoch 84/150, Loss: 16.2220\n",
      "Epoch 85/150, Loss: 14.4629\n",
      "Epoch 86/150, Loss: 14.9553\n",
      "Epoch 87/150, Loss: 14.8448\n",
      "Epoch 88/150, Loss: 14.6607\n",
      "Epoch 89/150, Loss: 14.6877\n",
      "Epoch 90/150, Loss: 12.5915\n",
      "Epoch 91/150, Loss: 14.2421\n",
      "Epoch 92/150, Loss: 10.6301\n",
      "Epoch 93/150, Loss: 12.0237\n",
      "Epoch 94/150, Loss: 12.2901\n",
      "Epoch 95/150, Loss: 12.7476\n",
      "Epoch 96/150, Loss: 12.1589\n",
      "Epoch 97/150, Loss: 12.2022\n",
      "Epoch 98/150, Loss: 11.5150\n",
      "Epoch 99/150, Loss: 10.8971\n",
      "Epoch 100/150, Loss: 11.1986\n",
      "Epoch 101/150, Loss: 11.5440\n",
      "Epoch 102/150, Loss: 11.4723\n",
      "Epoch 103/150, Loss: 10.7376\n",
      "Epoch 104/150, Loss: 10.1269\n",
      "Epoch 105/150, Loss: 9.6524\n",
      "Epoch 106/150, Loss: 9.4959\n",
      "Epoch 107/150, Loss: 10.1139\n",
      "Epoch 108/150, Loss: 8.3041\n",
      "Epoch 109/150, Loss: 8.1347\n",
      "Epoch 110/150, Loss: 9.0952\n",
      "Epoch 111/150, Loss: 9.2594\n",
      "Epoch 112/150, Loss: 8.0942\n",
      "Epoch 113/150, Loss: 8.8361\n",
      "Epoch 114/150, Loss: 7.8001\n",
      "Epoch 115/150, Loss: 8.2926\n",
      "Epoch 116/150, Loss: 7.5468\n",
      "Epoch 117/150, Loss: 7.0261\n",
      "Epoch 118/150, Loss: 5.6043\n",
      "Epoch 119/150, Loss: 5.8719\n",
      "Epoch 120/150, Loss: 6.1546\n",
      "Epoch 121/150, Loss: 6.5974\n",
      "Epoch 122/150, Loss: 5.2625\n",
      "Epoch 123/150, Loss: 4.6495\n",
      "Epoch 124/150, Loss: 4.1279\n",
      "Epoch 125/150, Loss: 4.4974\n",
      "Epoch 126/150, Loss: 4.2845\n",
      "Epoch 127/150, Loss: 4.3641\n",
      "Epoch 128/150, Loss: 3.8700\n",
      "Epoch 129/150, Loss: 2.9336\n",
      "Epoch 130/150, Loss: 2.9048\n",
      "Epoch 131/150, Loss: 3.0927\n",
      "Epoch 132/150, Loss: 2.4233\n",
      "Epoch 133/150, Loss: 1.9954\n",
      "Epoch 134/150, Loss: 2.1454\n",
      "Epoch 135/150, Loss: 1.7818\n",
      "Epoch 136/150, Loss: 2.3169\n",
      "Epoch 137/150, Loss: 1.8432\n",
      "Epoch 138/150, Loss: 2.0332\n",
      "Epoch 139/150, Loss: 1.2119\n",
      "Epoch 140/150, Loss: 0.9222\n",
      "Epoch 141/150, Loss: 1.1266\n",
      "Epoch 142/150, Loss: 0.9840\n",
      "Epoch 143/150, Loss: 1.4174\n",
      "Epoch 144/150, Loss: 1.4329\n",
      "Epoch 145/150, Loss: 1.1406\n",
      "Epoch 146/150, Loss: 0.7972\n",
      "Epoch 147/150, Loss: 0.4841\n",
      "Epoch 148/150, Loss: 0.0695\n",
      "Epoch 149/150, Loss: -0.0397\n",
      "Epoch 150/150, Loss: -0.2541\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"generated\", exist_ok=True)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Load and Preprocess\n",
    "\n",
    "# %%\n",
    "def load_and_preprocess_data(data_path='input/ML_data.csv'):\n",
    "    df = pd.read_csv(data_path).drop(columns=['Samples'])\n",
    "    df = df[~df['Cell_type'].isin(['Unknown'])]\n",
    "\n",
    "    feature_names = df.columns.drop('Cell_type')\n",
    "    le = LabelEncoder()\n",
    "    df['Cell_type'] = le.fit_transform(df['Cell_type'])\n",
    "    label_names = le.classes_\n",
    "    num_classes = len(label_names)\n",
    "\n",
    "    y = df['Cell_type'].values\n",
    "    X = df.drop(columns=['Cell_type']).values\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=64, shuffle=False)\n",
    "\n",
    "    return X, y, X_scaled, scaler, le, label_names, feature_names, num_classes, train_loader, val_loader\n",
    "\n",
    "X, y, X_scaled, scaler, le, label_names, feature_names, num_classes, train_loader, val_loader = load_and_preprocess_data()\n",
    "input_dim = X.shape[1]\n",
    "print(f\"Input dimension: {input_dim}, Number of classes: {num_classes}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Model Components\n",
    "\n",
    "# %%\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_features),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.LayerNorm(hidden_features),\n",
    "            nn.Linear(hidden_features, hidden_features),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_features, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class ActNorm(nn.Module):\n",
    "    def __init__(self, features, scale=1.0):\n",
    "        super().__init__()\n",
    "        self.initialized = False\n",
    "        self.scale = scale\n",
    "        self.register_parameter(\"bias\", nn.Parameter(torch.zeros(features)))\n",
    "        self.register_parameter(\"logs\", nn.Parameter(torch.zeros(features)))\n",
    "\n",
    "    def initialize(self, x):\n",
    "        with torch.no_grad():\n",
    "            mean = x.mean(0)\n",
    "            std = x.std(0)\n",
    "            self.bias.data.copy_(-mean)\n",
    "            self.logs.data.copy_(torch.log(self.scale / (std + 1e-6)))\n",
    "        self.initialized = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.initialized:\n",
    "            self.initialize(x)\n",
    "        z = (x + self.bias) * torch.exp(self.logs)\n",
    "        return z, self.logs.sum()\n",
    "\n",
    "    def inverse(self, z):\n",
    "        return (z * torch.exp(-self.logs)) - self.bias\n",
    "\n",
    "class InvertibleLinear(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        W = torch.nn.init.orthogonal_(torch.randn(dim, dim))\n",
    "        P, L, U = torch.lu_unpack(*W.lu())\n",
    "        self.register_buffer('P', P)\n",
    "        self.L = nn.Parameter(L)\n",
    "        self.S = nn.Parameter(U.diag())\n",
    "        self.U = nn.Parameter(torch.triu(U, diagonal=1))\n",
    "\n",
    "    def _assemble_W(self):\n",
    "        L = torch.tril(self.L, -1) + torch.eye(self.L.size(0), device=self.L.device)\n",
    "        U = torch.triu(self.U, 1) + torch.diag(self.S)\n",
    "        return self.P @ L @ U\n",
    "\n",
    "    def forward(self, x):\n",
    "        W = self._assemble_W()\n",
    "        return x @ W, torch.sum(torch.log(torch.abs(self.S)))\n",
    "\n",
    "    def inverse(self, z):\n",
    "        W = self._assemble_W()\n",
    "        return z @ torch.inverse(W)\n",
    "\n",
    "class AffineCoupling(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, mask, num_classes):\n",
    "        super().__init__()\n",
    "        self.mask = mask\n",
    "        self.embedding = nn.Embedding(num_classes, 8)\n",
    "        self.scale_net = MLP(input_dim + 8, hidden_dim, input_dim)\n",
    "        self.translate_net = MLP(input_dim + 8, hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x_masked = x * self.mask\n",
    "        y_embed = self.embedding(y)\n",
    "        x_cat = torch.cat([x_masked, y_embed], dim=1)\n",
    "        scale = self.scale_net(x_cat) * (1 - self.mask)\n",
    "        translate = self.translate_net(x_cat) * (1 - self.mask)\n",
    "        y_out = x_masked + (1 - self.mask) * (x * torch.exp(scale) + translate)\n",
    "        return y_out, scale.sum(1)\n",
    "\n",
    "    def inverse(self, y, label):\n",
    "        y_masked = y * self.mask\n",
    "        y_embed = self.embedding(label)\n",
    "        y_cat = torch.cat([y_masked, y_embed], dim=1)\n",
    "        scale = self.scale_net(y_cat) * (1 - self.mask)\n",
    "        translate = self.translate_net(y_cat) * (1 - self.mask)\n",
    "        x = y_masked + (1 - self.mask) * (y - translate) * torch.exp(-scale)\n",
    "        return x\n",
    "\n",
    "class GlowStep(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, mask, num_classes):\n",
    "        super().__init__()\n",
    "        self.actnorm = ActNorm(input_dim)\n",
    "        self.invconv = InvertibleLinear(input_dim)\n",
    "        self.coupling = AffineCoupling(input_dim, hidden_dim, mask, num_classes)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x, ldj1 = self.actnorm(x)\n",
    "        x, ldj2 = self.invconv(x)\n",
    "        x, ldj3 = self.coupling(x, y)\n",
    "        return x, ldj1 + ldj2 + ldj3\n",
    "\n",
    "    def inverse(self, z, y):\n",
    "        z = self.coupling.inverse(z, y)\n",
    "        z = self.invconv.inverse(z)\n",
    "        z = self.actnorm.inverse(z)\n",
    "        return z\n",
    "\n",
    "class ConditionalGLOW(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_flow_steps, num_classes):\n",
    "        super().__init__()\n",
    "        self.flow_steps = nn.ModuleList()\n",
    "        for i in range(n_flow_steps):\n",
    "            mask = torch.zeros(input_dim).to(device)\n",
    "            mask[i % 2::2] = 1\n",
    "            self.flow_steps.append(GlowStep(input_dim, hidden_dim, mask, num_classes))\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        log_det = 0\n",
    "        for step in self.flow_steps:\n",
    "            x, ldj = step(x, y)\n",
    "            log_det += ldj\n",
    "        return x, log_det\n",
    "\n",
    "    def inverse(self, z, y):\n",
    "        for step in reversed(self.flow_steps):\n",
    "            z = step.inverse(z, y)\n",
    "        return z\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Training\n",
    "\n",
    "# %%\n",
    "def train(model, train_loader, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            z, log_det = model(x_batch, y_batch)\n",
    "            log_prob = -0.5 * torch.sum(z ** 2, dim=1) - 0.5 * input_dim * np.log(2 * np.pi)\n",
    "            loss = -(log_prob + log_det).mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# %%\n",
    "hidden_dim = 128\n",
    "n_flow_steps = 16\n",
    "model = ConditionalGLOW(input_dim, hidden_dim, n_flow_steps, num_classes).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train(model, train_loader, optimizer, num_epochs=150)\n",
    "torch.save(model.state_dict(), \"generated/glow_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2dc319",
   "metadata": {},
   "source": [
    "# 5. Generate and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bab07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(model, class_id, num_samples):\n",
    "    z = torch.randn(num_samples, input_dim).to(device)\n",
    "    y = torch.full((num_samples,), class_id, dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        x_gen = model.inverse(z, y).cpu().numpy()\n",
    "    return x_gen\n",
    "\n",
    "def plot_real_vs_fake_per_class(X_scaled, y, scaler, model, label_names):\n",
    "    for cls_id in range(num_classes):\n",
    "        cls_name = label_names[cls_id]\n",
    "        real = X_scaled[y == cls_id]\n",
    "        fake = generate_synthetic_data(model, cls_id, len(real))\n",
    "\n",
    "        pca = PCA(n_components=2)\n",
    "        combined = np.vstack([real, fake])\n",
    "        pca_result = pca.fit_transform(combined)\n",
    "        real_pca = pca_result[:len(real)]\n",
    "        fake_pca = pca_result[len(real):]\n",
    "\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.scatter(real_pca[:, 0], real_pca[:, 1], label='Real', alpha=0.6)\n",
    "        plt.scatter(fake_pca[:, 0], fake_pca[:, 1], label='Fake', alpha=0.6)\n",
    "        plt.title(f'PCA: Real vs. Fake ({cls_name})')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"generated/pca_real_vs_fake_{cls_name}.png\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "# Plot PCA comparisons\n",
    "plot_real_vs_fake_per_class(X_scaled, y, scaler, model, label_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8195bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved synthetic data to 'generated/fake_data.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/miniconda3/envs/DeepN/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature distribution grid saved as 'generated/feature_distributions_grid.png'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_synthetic_data(model, scaler, le, n_per_class=500):\n",
    "    model.eval()\n",
    "    zs, labels = [], []\n",
    "    for class_idx in range(num_classes):\n",
    "        z = torch.randn(n_per_class, input_dim).to(device)\n",
    "        y = torch.full((n_per_class,), class_idx, dtype=torch.long).to(device)\n",
    "        x_fake = model.inverse(z, y).detach().cpu().numpy()\n",
    "        zs.append(x_fake)\n",
    "        labels.extend([class_idx] * n_per_class)\n",
    "\n",
    "    X_fake = np.vstack(zs)\n",
    "    y_fake = np.array(labels)\n",
    "    X_fake_rescaled = scaler.inverse_transform(X_fake)\n",
    "    df_fake = pd.DataFrame(X_fake_rescaled, columns=feature_names)\n",
    "    df_fake[\"Cell_type\"] = le.inverse_transform(y_fake)\n",
    "    df_fake.to_csv(\"generated/fake_data.csv\", index=False)\n",
    "    print(\"✅ Saved synthetic data to 'generated/fake_data.csv'\")\n",
    "    return df_fake\n",
    "\n",
    "df_fake = generate_synthetic_data(model, scaler, le)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Visualization: PCA Per Class + Feature Distribution\n",
    "\n",
    "def plot_pca_per_class(X_real, y_real, X_fake, y_fake, class_names, scaler, label_encoder):\n",
    "    pca = PCA(n_components=2)\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        real_mask = y_real == i\n",
    "        fake_mask = y_fake == i\n",
    "\n",
    "        if np.sum(real_mask) == 0 or np.sum(fake_mask) == 0:\n",
    "            continue\n",
    "\n",
    "        Xr = X_real[real_mask]\n",
    "        Xf = X_fake[fake_mask]\n",
    "        X_combined = np.vstack([Xr, Xf])\n",
    "        X_pca = pca.fit_transform(X_combined)\n",
    "\n",
    "        Xr_pca = X_pca[:len(Xr)]\n",
    "        Xf_pca = X_pca[len(Xr):]\n",
    "\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        plt.scatter(Xr_pca[:, 0], Xr_pca[:, 1], alpha=0.6, label=\"Real\", c='blue')\n",
    "        plt.scatter(Xf_pca[:, 0], Xf_pca[:, 1], alpha=0.6, label=\"Fake\", c='orange')\n",
    "        plt.title(f\"PCA: {class_name}\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"generated/pca_{class_name}.png\")\n",
    "        plt.close()\n",
    "\n",
    "def plot_feature_distributions_grid(df_real, df_fake, features, max_features=12, n_cols=4):\n",
    "    selected_features = features[:max_features]\n",
    "    n_feats = len(selected_features)\n",
    "    n_rows = (n_feats + n_cols - 1) // n_cols\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 3))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, feature in enumerate(selected_features):\n",
    "        ax = axes[idx]\n",
    "        sns.kdeplot(data=df_real, x=feature, label=\"Real\", fill=True, color=\"blue\", alpha=0.5, ax=ax)\n",
    "        sns.kdeplot(data=df_fake, x=feature, label=\"Fake\", fill=True, color=\"orange\", alpha=0.5, ax=ax)\n",
    "        ax.set_title(feature)\n",
    "        ax.legend()\n",
    "\n",
    "    # Hide any empty subplots\n",
    "    for i in range(n_feats, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"generated/feature_distributions_grid.png\")\n",
    "    plt.close()\n",
    "    print(f\"✅ Feature distribution grid saved as 'generated/feature_distributions_grid.png'\")\n",
    "\n",
    "\n",
    "\n",
    "def plot_feature_distributions(X_real_df, X_fake_df, features, class_names):\n",
    "    for feature in features:\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        sns.kdeplot(data=X_real_df, x=feature, label=\"Real\", fill=True, color=\"blue\", alpha=0.5)\n",
    "        sns.kdeplot(data=X_fake_df, x=feature, label=\"Fake\", fill=True, color=\"orange\", alpha=0.5)\n",
    "        plt.title(f\"Feature Distribution: {feature}\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"generated/feature_dist_{feature}.png\")\n",
    "        plt.close()\n",
    "\n",
    "# Prepare for plotting\n",
    "df_real = pd.DataFrame(scaler.inverse_transform(X_scaled), columns=feature_names)\n",
    "df_real[\"Cell_type\"] = le.inverse_transform(y)\n",
    "df_fake = pd.read_csv(\"generated/fake_data.csv\")\n",
    "X_fake = scaler.transform(df_fake[feature_names])\n",
    "y_fake = le.transform(df_fake[\"Cell_type\"])\n",
    "\n",
    "plot_pca_per_class(X_scaled, y, X_fake, y_fake, label_names, scaler, le)\n",
    "#plot_feature_distributions(df_real, df_fake, feature_names, label_names)\n",
    "plot_feature_distributions_grid(df_real, df_fake, feature_names, max_features=12, n_cols=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
